# 自我介绍

---

面试官你好，我叫杨礼铭，目前就读与华南理工大学计算机学院，研究生三年级，研究方向**多模态融合的移动机器人导航方法**，

主要解决机器人在自然语言指令下依靠多种传感器进行导航所产生的问题。

在校期间我作为核心成员参加了研电赛，获得全国总决赛二等奖和安谋企业专项一等奖；

还参加了昇腾AI创新大赛，获得了广州赛区铜奖；

也参与过学院评奖评优，获得研究生腾讯企业一等奖学金和两次优秀学生二等奖学金

在校期间我也参与了很多课题项目，如智能居家监护系统、公路局的路面病害识别等

我认为自己有很好的持续学习能力和信息检索能力，可以在短时间内学习项目需要的技术，

在遇到的技术问题时能通过官方文档或国内外技术论坛快速解决；



# 面向独居老人的智能居家监护系统

---

## 项目背景

我国人口老龄化程度加深，市面上面向老人的监护产品存在不足，独居老人发生意外的风险更高，所以我们设计了面向独居老人的智能居家监护系统；

## 功能

我们的系统主要由**云端服务器**、**姿态检测模块**、**语音识别模块**、**机器人联动服务**模块和**微信小程序**组成。

云端服务器负责整个系统的通信，姿态检测模块和语音识别模块检测老人是否发生异常状态。

服务机器人的主要功能为响应老人的语音需求，比如老人喊一声“喝水”，机器人就能带着水来到老人身边；以及在老人出现异常状况时自动寻找并到达老人身边，送来急救药物和拍摄现场照片。

微信小程序让家人可以远程监护老人的状态。

## 主要工作

1. 构思项目的功能需求，设计系统的总体架构，探索各个功能模块的技术可行性；
2. 姿态检测模块的所有功能开发，如点云数据的采集与标注、网络模型的创建与修改、检测模型的剪支优化和检测出异常时触发的报警功能。
3. 参与部分的机器人功能开发，如多传感器融合的自动寻人功能。

## 最大的挑战

---

在确定参加研电赛后的那段时间是比较困难的，从最开始的选题、功能设计、系统设计，到具体的分工、开发实现和后续的测试各个环节都充满了大大小小的问题

在测试移动机器人的自动寻人功能过程中，发现了很严重的检测时延，导致测试的结果很不理想，这个问题又涉及了通信、识别模型、机器人导航多个模块，我们三个人一起花了整整3天时间去测试定位并解决问题，设计了多个解决方案如“优化检测模块的网络模型”、“设计二阶段检测算法”，最终才解决时延这一问题。但回过头来看，我更认为这是一种很好的磨练与挑战，提升我的编程硬能力和团队协作软能力。

## 踩过的坑

1.在拿到DK610开发板后，直接装了官方提供的Fedora**<u>系统</u>**，在装机器人操作系统ROS的时候就出现了问题，初始化时一直无法下载完整的资源，测试节点都无法正常启动，后来知道是系统的原因导致无法安装，但官方不提供ubuntu镜像；又因为架构不同导致烧普通的ubuntu镜像出现各种奇奇怪怪的问题；最后通过用别的厂商的CPU相同的开发板的内核和ubuntu构建脚本，把DK610内核里的设备树搬过去构建，才刷好了ubuntu系统

2.在搭建**<u>姿态检测网络模型</u>**的时候，受限于DK610的算力，导致我基于pytorch设计的网络模型在开发板上检测效率很低，后来也试过在腾讯开源的NCNN和Tensorflow框架下开发（在这过程中出现了各种疑难杂症）结果检测效率还是不行，最后在检测部分改用了tensorflowlite框架，通过将pytorch训练好的.pt模型文件压缩成.tflite模型才能进行高效的推理。

## 优化

**<u>机器人寻人模型的优化</u>**：对于整个系统而言，我们要保证在异常情况发生时，各模块都需要具备非常快响应速度，我们的系统在检测出异常到微信小程序显示报警信息仅需1-2s，但是移动机器人需要30s左右的时候寻找目标并回传现场照片，效率比较低。后来经过测试我发现搭载在机器人上的DK610开发板上的高性能边缘推理引擎Tengine提供tensorflow模型加速的接口（传入模型就可以加速推理），在修改框架、转换模型之后，又将视觉算法库opencv替换成arm架构下简洁高效的视觉算法库FastCV，让检测时延从2s降低到0.5s左右，整个寻人过程只需15-20s，大幅提高了系统整体效率。



# WEBSERVER

---

## 介绍

这个项⽬是我在学习计算机⽹络和网络编程过程中开发的轻量级Web服务器，实现用户的登录注册以及请求图片、视频等资源；服务器的⽹络模型实现了reactor和同步io（只负责监听是否有事件发生）模拟proactor（主线程负责接受新连接、读写数据，工作线程负责业务逻辑）加线程池的模式，IO处理使⽤了⾮阻塞IO和IO多路复⽤技术，具备并发处理客户端的http请求的能力；

项⽬中的⼯作可以分为两部分，⼀部分是服务器⽹络框架等⼀些基本系统的搭建，另⼀部分是为了提⾼服务器性能所做的⼀些优化，⽐如实现异步日志io，使用数据库连接池，定时器处理非活动连接机制。最后使用webbench对服务器进行压⼒测试，对监听socket和连接socket分别使用ET和LT模式测试，都可以实现上万的并发连接。

## 为什么做

项目是在学习计网的过程中逐步搭建的，这个项⽬综合性⽐较强，从中既能学习Linux环境下的⼀些系统调⽤，也能熟悉⽹络编程和⼀些⽹络框架，其中也根据⾃⼰的理解加⼊了⼀些性能调优的⼿段。

## 优化

1. 使用线程池、数据库连接池，减少系统频繁创建断开异步工作线程和数据库连接的开销，并且用RAII机制管理数据库连接；

3. 使用定时器关闭超时的非活动连接，防止连接长时间不交换数据，占用服务器端的文件描述符，浪费系统资源；（初始传送间隔默认为5s，连接的过期时间是3*5=15s）

4. 一个针对定时器的优化：alarm函数中传入的时间参数由静态改为动态，减少了不必要的信号触发浪费：如果以静态的时间参数触发SIGALRM信号，调用定时器处理函数会造成触发浪费，比如当前静态时间参数是5ms，即每隔5ms触发一次SIGALRM，如果当前即将超时的连接距离现在还有20ms，那么在这期间，SIGALRM信号触发了4次，定时器处理函数执行了4次，可是前三次都是没有意义的；因此采用动态的时间参数去优化，每次调用定时器处理函数后，将时间参数设置为最近超时时间与当前时间的时间差（因为定时器使用升序链表维护，所以表头的超时时间就是最近超时时间），这样就会减少触发浪费的现象，也减少了用户态和内核态之间的切换，因为一次信号处理需要用户态->内核态->用户态->内核态->用户态。

   信号处理完整过程：

   - 设置信号传送闹钟，进程收到信号后OS中断当前进程到内核，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
   
   - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。（屏蔽信号处理信号）
   
   - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
   
   - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。
   
     #### 继续优化方向：
   
     实现异步日志io，防止io阻塞导致服务器并发能力降低，webbench测试在10000个客户端连接5s的情况下，异步日志QPS（每秒响应请求数）能达到97000多，数据量达到一千多万比特每秒，相比同步日志提高了10%；
   
     （单例模式获取唯一的日志系统实例，生产消费者模型，通过异步线程写入日志文件）

## 坑

客户端请求视频时，视频播放不完整或出错；

检查的时候发现请求小文件没问题，大文件出问题，就把问题锁定在writev（）的使用：

我原本在报文相响应的while循环中只调用了writev，对返回值做异常情况处理，当请求小文件时，writev能够一次写完缓冲区的文件；当请求大文件时，受到文件描述符写缓冲区大小的限制，需要多次调用writev，通过打印日志查看每次发送的资源地址查到，每次调用writev发送的资源都和第一次发送的资源一模一样，于是就定位到问题出在iovec动态数组（数组中的元素是使用结构体保存的响应报文和响应数据:len+指针）在每次传输后并不会自动偏移指针和传输长度，导致了每次调用writev都按原来的指针和长度发送数据；

修正方法：每次调用writev后都更新iovec中下次传输的文件起始位置和长度。



# 路面病害识别

## 功能需求

通过甲方提供的数据集 ，训练一个能够在嵌入式平台上部署的轻量化实时检测路面病害类别的模型 ，达到正检率的要求，并实现跟车实时检测

流程：筛选、标注数据集->训练推理模型->对比不同模型的检测结果->优化各类参数->转换模型并部署在atlas200dkA2上（社区有提供yolov3部署案例，但yolov5需要自己改写接口，自己部署）->测试

## 主要工作

1. 负责数据集的筛选、标注 ，对比三种不同算法（yolov5、yolov3数据增强版、yolov3无数据增强版）

   的训练结果、并将测试的结果可视化 ；

2. 分析结果，优化标注过程，改进网络结构和调整训练参数，最终在昇腾ai开发板atlas200dk A2上部署模型，测试检测结果。

## 成果

处理整合过近**1TB**的超大数据集，使模型的最优**正检率达89%**以上，**提高了约20%**；通过剪枝目标检测模型克服嵌入式设备算力有限检测耗时长的问题，使**检测速度提高37%**。（15帧提高到了20帧）

## 最大的挑战

---

因为mindspore框架开发还不完善，相关文档、论坛都不齐全，所以在**更换检测框架**这一步的时候耗费了很多精力

在最开始开发时，我以为只是单纯的测试+模型、方法调优，所以都是在服务器上通过docker配置好的pytorch环境中去训练测试，但后面说需要在华为提供的atlas200dk上部署，要重新学习mindspore深度学习框架，修改各种api。因为当时昇腾社区还没有提供yolov5的检测算法包，我就按着残缺的官方文档试着把yolov5的源码都修改到mindspore框架下，修改完之后经常发现缺少了某些算子的支持，导致数据加载异常，（比如使用embedding层时（词嵌入向量操作）报错缺少了padding操作，去社区提问后，才知道要手动将embedding的`padding_idx`位置对应的权重初始化为0，并且在训练时通过`mask`的操作，过滤掉`padding_idx`位置对应的loss，去解决这个问题；再比如说代码在cpu上跑没问题，但在利用Ascend加速训练时却报错，社区提问后才知道这些算子还有使用限制）

## 踩过的坑

后期部署模型时，需要将pytorch框架下训练好的.pt模型通过昇腾张量编译器（ATC工具）转换成昇腾AI处理器支持的.om模型文件；最开始转换好模型，通过输入视频流去测试时发现，检测的结果完全不能匹配，对照官方文档写的指令都没问题

后面通过社区提问才知道**还需要添加最后一个输出节点的名称作为参数**，这才顺利地部署在开发板上，可以进行实时的检测。

## 优化

1. 通过检查数据集我们发现有很多错标、漏标的情况，我就统计残缺的数据集，并按照标准**重新标注**。

2. 经过我们的测试，没有数据增强的准确率只有30%，具有数据增强的准确率达到了70%，训练模型是否具有数据增强，对标签为2的目标的检测精确率具有重大影响。所以在参数的设置中，添加**数据增强**可以有效地提高整体正检率。

   **后续的优化方向**：通过训练的结果明显看出：当训练集中目标标签数量少，或图片未标全（如标签300、400）时，三个算法模型都出现完全无法预测该类标签的情况。（准确率为0）我们通过减少不同类别数据量的差距，可以提高整体正检率。







# hr

# 自我介绍

---

面试官你好，我叫杨礼铭，目前就读与华南理工大学计算机学院，研究生三年级，

在校期间我作为核心成员参加了研电赛，获得全国总决赛二等奖和安谋企业专项一等奖；

还参加了昇腾AI创新大赛，获得了广州赛区铜奖；

也参与过学院评奖评优，获得研究生腾讯企业一等奖学金和两次优秀学生二等奖学金

在校期间我也参与了很多课题项目，如智能居家监护系统、公路局的路面病害识别、轻量级webserver等

我认为自己有很好的持续学习能力和信息检索能力，可以在短时间内学习项目需要的技术，

在遇到的技术问题时（电赛模块迁移至华为开发板时，改框架、转模型）能通过官方文档或国内外技术论坛快速解决；

我本人也非常希望能够通过今天的面试成为你们的一员。

## 为什么选择信锐&公司简介

就方向而言，我觉得传统的纯互联网企业虽然给的钱多，但都不稳定不靠谱，大厂裁员屡见不鲜，都开玩笑地说pdd是职业的最后一站。

信锐网科技术有限公司是深信服集团旗下的全资子公司（有自己明确的主营业务和发展方向，个人比较看好人联网、物联网这一方向，这也是我选择信锐最主要的原因；其次相较于大厂而言，信锐能开的薪资也不低，收入方面有保障，这也是重要因素。（研究生25w/sp44w））

主要业务方向是提供面向未来的网络连接产品及解决方案。

以人联网、物联网为方向，构建万物互联、万物智联的未来

## 为什么选择这个岗位C/C++软件开发工程师

面试的时候也有询问过部门的主营方向（做管理平台、网络智能化相关的方向）和对应届生的要求：网络、linux系统；

再结合招聘要求的专业知识，我觉得自己很匹配这一岗位，

我本身专精于c/c++这一语言，然后对网络、linux系统等方面的基础知识掌握的还算扎实，也有相应的项目比赛经验。

## 职业规划

自身喜欢物联网设备、智能化开发这一工作方向，本身实验室也是做这一方向的，岗位来说会十分匹配

对于职业规划来说就是向深根于靠谱的公司，从着手新手项目开始，然后逐步积累项目知识，到能独当一面的技术人员

## 自身缺点

对任务比较较真，比如电赛实验测试过程中，发现了某个问题就一心想着解决，经常错过饭店，导致偶尔会胃痛

我虽然基础专业技能方面不错，但是实战经验可能并不足够

## 对加班的看法

如果工作需要我会义不容辞加班的，但同时我也争取提高自己的工作效率，尽量在规定时间内完成，减少不必要的加班

## 是否有其他offer

前几天睿联的hr有给我发意向通知

睿联也是做物联网设备的公司，但他岗位是ios开发，技术栈有部分不是特别的匹配，薪资等级好像也没有信锐给的高

## 期望薪资



## 成果



# 实习

---

在小米负责的其中一个项目是表盘的条件控制功能。

表现为对用户交互、数据变化的响应，比如点击屏幕、抬腕亮屏或数据源的值满足预设条件后，控制表盘的部件槽显示对应小部件，或者触发小部件动画。

目的：增加表盘的表现形式，比如制作日出日落主题表盘，表盘中有展示日出日落的弧形进度条，白天的进度条符号是太阳，夜晚是月亮。

## 难点

1. 读懂表盘从加载到渲染的整体业务流程，包括表盘资源的解析、渲染，数据源的订阅管理等逻辑。
2. 与产品协商功能需求，确保条件控制逻辑能够满足未来表盘可能需要的表现形式，以及功能的扩展性（提议升级固件协议，将条件抽象成表盘资源，而非在部件槽或小部件中分别实现，方便未来将条件控制扩展到其他资源上）。
3. 联调时经常出现前端提供的表盘资源文件不符合协议的问题，解决起来耗费时间，所以用c++写了个测试工具，可视化表盘按协议读取二进制文件的结果，并提示可能出错的结构体成员，后用于所有表盘资源的检测。

## 实现的大致流程

1.  渲染部件槽或小部件时注册其中的条件和满足条件时的回调函数，该回调函数负责切换小部件或播放动画；
2.  在注册条件时订阅所需的数据源或事件和对应的回调函数，该回调函数负责判断条件是否为真。

于是订阅的数据源或事件发生变化时，触发其对应的回调函数进行条件判断，条件判断为真时触发条件回调函数，最终实现小部件的切换或播放动画。

## 踩过的坑

### 背景

一个表盘的图片、条件、小部件等资源由各自结构体定义并存放在二进制文件中。表盘渲染之前需要加载表盘二进制文件；

### 现象

加载过程中结构体按照协议读取二进制文件时，内容不符合预期。

### 问题

1. 对零长度数组的使用错误：其中一个结构体末尾有两个零长度数组，想当然地使用数组名去访问第二个数组，然而，由于第一个零长度数组占用空间的不确定性，编译器并不知道第二个数组的起始地址，因此想要访问第二个零长度数组只能通过手动偏移指针来实现。
2. 内存对齐问题：打开二进制文件对照地址检查，发现从某些结构体成员开始产生整体偏移，分析发现本地编译器默认四字节对齐优化，一些成员因内存对齐产生了偏移。解决办法是使用\_\_attribute__ ((packed))，取消结构体编译时的内存对齐优化，也就是一字节对齐。虽然会有读取性能损耗，但是避免了跨平台编译时不同平台的不同内存对齐方式导致的错误，其次考虑到二进制文件的加载不频繁，损耗可忽略。

## 调试方法

- 代码静态分析：coverity
  - 内存泄漏、常量溢出、缓冲区溢出、使用未初始化变量、空指针引用
  - 原理：考虑代码中条件语句、循环以及分支等结构可能导致的不同执行路径，在每个可能的执行路径上进行数据流分析（跟踪变量的使用赋值、生命周期等）或控制流分析。
- 动态内存检测：addressSanitizer（ASAN）
  - 原理：
    - 在编译时将额外的代码插入到目标程序中，对内存的分配释放/读写操作进行检测和记录；
    - 运行时会接管malloc和free函数。malloc执行完后，已分配或释放的内存的会被标记，且暂时不会分配出去。运行时，ASan会监测内存访问，一旦发现内存访问错误，比如越界访问、释放后再次访问等，会立即输出错误信息并中断程序执行。
- 在线调试：gdb（虚拟机上用）
  - 监视或改变运行时内部状态
  - 打断点，根据调用栈来读懂代码运行逻辑
- 离线调试：core dump（虚拟机上用）
  - core文件：程序异常终止时，操作系统将程序的内存映像转储到core文件，包括调用栈，堆区，全局变量等
  - 使用：用gdb加载程序和core文件，backtrace还原崩溃时的调用栈
- 离线调试：backtrace（真机上用）
  - vela引入实时backtrace的支持
  - 作用：程序出错时打印出函数的调用堆栈，列出当前函数调用关系
  - 原理：用栈指针遍历栈内存，查找函数调用历史