# 自我介绍

---

我叫杨礼铭，目前就读与华南理工大学计算机学院，研究生三年级，研究方向**多模态融合的移动机器人导航方法**，主要解决机器人在自然语言指令下依靠多种传感器进行导航所产生的问题。

在校期间我参加了研电赛，并获得全国总决赛二等奖和安谋专项企业奖一等奖；

还参加了昇腾AI创新大赛，获得了广州赛区铜奖；

也参与过学院评奖评优，获得过研究生腾讯企业一等奖学金和优秀学生二等奖学金

我认为自己有一定的信息检索能力，遇到的技术问题基本能快速通过国内外论坛解决；

同时我也具有良好的自我驱动学习能力，可以在短时间内学习项目需要的技术并实践；



# 面向独居老人的智能居家监护系统

---

## 项目背景

我国人口老龄化程度加深，市面上面向老人的监护产品存在不足，独居老人发生意外的风险更高，所以我们设计了面向独居老人的智能居家监护系统；

## 功能

我们的系统主要由云端服务器、姿态检测模块、语音识别模块、机器人联动服务模块和微信小程序组成。

云端服务器负责整个系统的通信，姿态检测模块和语音识别模块检测老人是否发生异常状态。

服务机器人的主要功能为响应老人的语音需求，比如老人喊一声“喝水”，机器人就能带着水来到老人身边；以及在老人出现异常状况时自动寻找并到达老人身边，送来急救药物和拍摄现场照片。

微信小程序让家人可以远程监护老人的状态。

## 主要工作

1. 构思项目的功能需求，设计系统的总体架构，探索各个功能模块的技术可行性；
2. 姿态检测模块的所有功能开发，如点云数据的采集与标注、网络模型的创建与修改、检测模型的剪支优化和检测出异常时触发的报警功能。
3. 参与部分的机器人功能开发，如多传感器融合的自动寻人功能。

## 最大的挑战

---

在确定参加研电赛后的那段时间是比较困难的，从最开始的选题、功能设计、系统设计，到具体的分工、开发实现和后续的测试各个环节都充满了大大小小的问题

在第一次系统测试的过程中，发现了很严重的时延，导致测试的结果很不理想，这个问题又涉及了通信、识别模型、机器人导航多个模块，我们三个人一起花了整整3天时间去测试定位并解决问题，设计了多个解决方案如“优化检测模块的网络模型”、“设计二阶段检测算法”，最终才解决时延这一问题。但回过头来看，我更认为这是一种很好的磨练与挑战，提升我的编程硬能力和团队协作软能力。

## 踩过的坑

1.在拿到DK610开发板后，直接装了官方提供的Fedora系统，在装机器人操作系统ROS的时候就出现了问题，初始化时一直无法下载完整的资源，测试节点都无法正常启动，后来知道是系统的原因导致无法安装，但官方不提供ubuntu镜像；又因为架构不同导致烧普通的ubuntu镜像出现各种奇奇怪怪的问题；最后通过用别的厂商的CPU相同的开发板的内核和ubuntu构建脚本，把DK610内核里的设备树搬过去构建，才刷好了ubuntu系统

2.在搭建网络模型的时候，受限于DK610的算力，导致我基于pytorch设计的网络模型在开发板上检测效率很低，后来也试过在腾讯开源的NCNN和Tensorflow框架下开发（在这过程中出现了各种疑难杂症）结果检测效率还是不行，最后在检测部分改用了tensorflowlite框架，通过将pytorch训练好的.pt模型文件压缩成.tflite模型才能进行高效的推理。



# WEBSERVER

---

## 介绍

这个项⽬是我在学习计算机⽹络和网络编程过程中开发的轻量级Web服务器，实现用户的登录注册以及请求图片、视频等资源；服务器的⽹络模型实现了reactor和同步io（只负责监听是否有事件发生）模拟proactor（主线程负责接受新连接、读写数据，工作线程负责业务逻辑）加线程池的模式，IO处理使⽤了⾮阻塞IO和IO多路复⽤技术，具备并发处理客户端的http请求的能力；

项⽬中的⼯作可以分为两部分，⼀部分是服务器⽹络框架等⼀些基本系统的搭建，另⼀部分是为了提⾼服务器性能所做的⼀些优化，⽐如实现异步日志io，使用数据库连接池，定时器处理非活动连接机制。最后使用webbench对服务器进行压⼒测试，对监听socket和连接socket分别使用ET和LT模式测试，都可以实现上万的并发连接。

## 为什么做

项目是在学习计网的过程中逐步搭建的，这个项⽬综合性⽐较强，从中既能学习Linux环境下的⼀些系统调⽤，也能熟悉⽹络编程和⼀些⽹络框架，其中也根据⾃⼰的理解加⼊了⼀些性能调优的⼿段。

## 优化

1. 使用线程池、数据库连接池，减少系统频繁创建断开异步工作线程和数据库连接的开销，并且用RAII机制管理数据库连接；

2. 实现异步日志io，防止io阻塞导致服务器并发能力降低，webbench测试在10000个客户端连接5s的情况下，异步日志QPS（每秒响应请求数）能达到97000多，数据量达到一千多万比特每秒，相比同步日志提高了10%；

   （单例模式获取唯一的日志系统实例，生产消费者模型，通过异步线程写入日志文件）

3. 使用定时器关闭超时的非活动连接，防止连接长时间不交换数据，占用服务器端的文件描述符，浪费系统资源；（初始传送间隔默认为5s，连接的过期时间是3*5=15s）

4. 一个针对定时器的优化：alarm函数中传入的时间参数由静态改为动态，减少了不必要的信号触发浪费：如果以静态的时间参数触发SIGALRM信号，调用定时器处理函数会造成触发浪费，比如当前静态时间参数是5ms，即每隔5ms触发一次SIGALRM，如果当前即将超时的连接距离现在还有20ms，那么在这期间，SIGALRM信号触发了4次，定时器处理函数执行了4次，可是前三次都是没有意义的；因此采用动态的时间参数去优化，每次调用定时器处理函数后，将时间参数设置为最近超时时间与当前时间的时间差（因为定时器使用升序链表维护，所以表头的超时时间就是最近超时时间），这样就会减少触发浪费的现象，也减少了用户态和内核态之间的切换，因为一次信号处理需要用户态->内核态->用户态->内核态->用户态。

   信号处理完整过程：

   - 设置信号传送闹钟，进程收到信号后OS中断当前进程到内核，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
   - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。（屏蔽信号处理信号）
   - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
   - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

## 坑

客户端请求视频时，视频播放不完整或出错；

检查的时候发现请求小文件没问题，大文件出问题，就把问题锁定在writev（）的使用：

我原本在报文相响应的while循环中只调用了writev，对返回值做异常情况处理，当请求小文件时，writev能够一次写完缓冲区的文件；当请求大文件时，受到文件描述符写缓冲区大小的限制，需要多次调用writev，通过打印日志查看每次发送的资源地址查到，每次调用writev发送的资源都和第一次发送的资源一模一样，于是就定位到问题出在iovec动态数组（数组中的元素是使用结构体保存的响应报文和响应数据:len+指针）在每次传输后并不会自动偏移指针和传输长度，导致了每次调用writev都按原来的指针和长度发送数据；

修正方法：每次调用writev后都更新iovec中下次传输的文件起始位置和长度。



















# 实习

---

在小米负责的其中一个项目是表盘的条件控制功能。

表现为对用户交互、数据变化的响应，比如点击屏幕、抬腕亮屏或数据源的值满足预设条件后，控制表盘的部件槽显示对应小部件，或者触发小部件动画。

目的：增加表盘的表现形式，比如制作日出日落主题表盘，表盘中有展示日出日落的弧形进度条，白天的进度条符号是太阳，夜晚是月亮。

## 难点

1. 读懂表盘从加载到渲染的整体业务流程，包括表盘资源的解析、渲染，数据源的订阅管理等逻辑。
2. 与产品协商功能需求，确保条件控制逻辑能够满足未来表盘可能需要的表现形式，以及功能的扩展性（提议升级固件协议，将条件抽象成表盘资源，而非在部件槽或小部件中分别实现，方便未来将条件控制扩展到其他资源上）。
3. 联调时经常出现前端提供的表盘资源文件不符合协议的问题，解决起来耗费时间，所以用c++写了个测试工具，可视化表盘按协议读取二进制文件的结果，并提示可能出错的结构体成员，后用于所有表盘资源的检测。

## 实现的大致流程

1.  渲染部件槽或小部件时注册其中的条件和满足条件时的回调函数，该回调函数负责切换小部件或播放动画；
2.  在注册条件时订阅所需的数据源或事件和对应的回调函数，该回调函数负责判断条件是否为真。

于是订阅的数据源或事件发生变化时，触发其对应的回调函数进行条件判断，条件判断为真时触发条件回调函数，最终实现小部件的切换或播放动画。

## 踩过的坑

### 背景

一个表盘的图片、条件、小部件等资源由各自结构体定义并存放在二进制文件中。表盘渲染之前需要加载表盘二进制文件；

### 现象

加载过程中结构体按照协议读取二进制文件时，内容不符合预期。

### 问题

1. 对零长度数组的使用错误：其中一个结构体末尾有两个零长度数组，想当然地使用数组名去访问第二个数组，然而，由于第一个零长度数组占用空间的不确定性，编译器并不知道第二个数组的起始地址，因此想要访问第二个零长度数组只能通过手动偏移指针来实现。
2. 内存对齐问题：打开二进制文件对照地址检查，发现从某些结构体成员开始产生整体偏移，分析发现本地编译器默认四字节对齐优化，一些成员因内存对齐产生了偏移。解决办法是使用\_\_attribute__ ((packed))，取消结构体编译时的内存对齐优化，也就是一字节对齐。虽然会有读取性能损耗，但是避免了跨平台编译时不同平台的不同内存对齐方式导致的错误，其次考虑到二进制文件的加载不频繁，损耗可忽略。

## 调试方法

- 代码静态分析：coverity
  - 内存泄漏、常量溢出、缓冲区溢出、使用未初始化变量、空指针引用
  - 原理：考虑代码中条件语句、循环以及分支等结构可能导致的不同执行路径，在每个可能的执行路径上进行数据流分析（跟踪变量的使用赋值、生命周期等）或控制流分析。
- 动态内存检测：addressSanitizer（ASAN）
  - 原理：
    - 在编译时将额外的代码插入到目标程序中，对内存的分配释放/读写操作进行检测和记录；
    - 运行时会接管malloc和free函数。malloc执行完后，已分配或释放的内存的会被标记，且暂时不会分配出去。运行时，ASan会监测内存访问，一旦发现内存访问错误，比如越界访问、释放后再次访问等，会立即输出错误信息并中断程序执行。
- 在线调试：gdb（虚拟机上用）
  - 监视或改变运行时内部状态
  - 打断点，根据调用栈来读懂代码运行逻辑
- 离线调试：core dump（虚拟机上用）
  - core文件：程序异常终止时，操作系统将程序的内存映像转储到core文件，包括调用栈，堆区，全局变量等
  - 使用：用gdb加载程序和core文件，backtrace还原崩溃时的调用栈
- 离线调试：backtrace（真机上用）
  - vela引入实时backtrace的支持
  - 作用：程序出错时打印出函数的调用堆栈，列出当前函数调用关系
  - 原理：用栈指针遍历栈内存，查找函数调用历史